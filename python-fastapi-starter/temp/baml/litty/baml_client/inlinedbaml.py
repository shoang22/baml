###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "analyze_books.baml": "\nclass Score {\n  year int @description(#\"\n    The year you're giving the score for.\n  \"#)\n  score int @description(#\"\n    1 to 100\n  \"#)\n}\n\nclass PopularityOverTime {\n  bookName string\n  scores Score[]\n}\n\nclass WordCount {\n  bookName string\n  count int\n}\n\nclass Ranking {\n  bookName string\n  score int @description(#\"\n    1 to 100 of your own personal score of this book\n  \"#)\n}\n \nclass BookAnalysis {\n  bookNames string[] @description(#\"\n    The list of book names  provided\n  \"#)\n  popularityOverTime PopularityOverTime[] @description(#\"\n    Print the popularity of EACH BOOK over time.\n  \"#) @alias(\"popularityData\")\n  // popularityRankings Ranking[] @description(#\"\n  //   A list of the book's popularity rankings over time. \n  //   The first element is the top ranking\n  // \"#)\n \n  // wordCounts WordCount[]\n}\n\nfunction AnalyzeBooks(input: string) -> BookAnalysis {\n  client CustomCodeQwen1_5\n  prompt #\"\n    Analyze the following book list and provide the information in the schema. If you don't know the exact answer, take a guess.\n    BOOK_LIST:\n    {{ input }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\ntest TestName {\n  functions [AnalyzeBooks]\n  args {\n    input #\"\n      brave new world\n      the lord of the rings\n      three body problem\n      stormlight archive\n    \"#\n  }\n}\n",
    "clients.baml": "client<llm> GPT4 {\n  provider openai\n  options {\n    model gpt-4\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> GPT4Turbo {\n  provider openai\n  options {\n    model gpt-4-turbo\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> GPT4o {\n  provider openai\n  options {\n    model gpt-4o\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n\nclient<llm> GPT3 {\n  provider baml-openai-chat\n  options {\n    model gpt-3.5-turbo\n    api_key env.OPENAI_API_KEY\n  }\n}   \n\n\nclient<llm> CustomCodeQwen1_5 {\n  provider openai-generic \n  options {\n    base_url \"http://localhost:8080/v1\"\n  }\n}",
}

def get_baml_files():
    return file_map